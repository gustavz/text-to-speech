{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bark: text-to-speech using LLMs \n",
    "\n",
    "project: https://github.com/suno-ai/bark\n",
    "\n",
    "examples: https://suno-ai.notion.site/Bark-Examples-5edae8b02a604b54a42244ba45ebc2e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bark import SAMPLE_RATE, generate_audio, preload_models\n",
    "from scipy.io.wavfile import write as write_wav\n",
    "from IPython.display import Audio\n",
    "\n",
    "# download and load all models\n",
    "preload_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select voice\n",
    "voice_preset = \"v2/en_speaker_1\"\n",
    "\n",
    "# generate audio from text\n",
    "text_prompt = \"\"\"\n",
    "DataChad is an open-source project that allows users to ask questions about any data source.\n",
    "It leverages embeddings, Deep Lake as a vector database, large language models like GPT-3.5-turbo or GPT-4 and LangChain. \n",
    "\n",
    "The data source can be anything from a local file like a pdf or CSV, a website url, \n",
    "a GitHub repository, or even the path to a directory, scanned recursively if the app is deployed locally.\n",
    "\n",
    "Subsequently, the app detects and loads the data source into text documents, \n",
    "embeds the text documents using OpenAI embeddings, \n",
    "then stores them embeddings as a vector dataset to Activeloop's Deep Lake Cloud. \n",
    "\n",
    "A Langchain is established, comprising an LLM model and the embedding database index as a retriever. \n",
    "\n",
    "This chain serves as the context for answering user queries over any data they upload.\n",
    "\"\"\"\n",
    "audio_array = generate_audio(text_prompt, history_prompt=voice_preset)\n",
    "\n",
    "# save audio to disk\n",
    "write_wav(\"woof.wav\", SAMPLE_RATE, audio_array)\n",
    "  \n",
    "# play text in notebook\n",
    "Audio(audio_array, rate=SAMPLE_RATE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
